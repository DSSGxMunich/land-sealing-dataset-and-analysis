{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T14:53:31.657451748Z",
     "start_time": "2023-08-29T14:53:31.110286947Z"
    }
   },
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import os\n",
    "\n",
    "from data_pipeline.pdf_scraper.tika_pdf_scraper import pdf_parser_from_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustration of usage of tika_pdf_scraper.py\n",
    "\n",
    "This pdf scraper assumes to-be-scraped documents to be present in a subfolder in the same project (here: `../../data/nrw/pdfs`). Due to storage constraints, the pdfs have however not been uploaded to this Github repository. Make sure to provide files before running the code. While Apache tika technically allows scraping based on URLs too, here, pre-processing is applied to the pdfs to improve performance of the scraper. Therefore, the pdf scraper expects a folder containing the files (in .pdf or .png format) as input.\n",
    "\n",
    "To use the pdf scraper:\n",
    "- Install java (we originally used version 20.0.2, [link](https://www.oracle.com/java/technologies/downloads/)\n",
    "- **Adjust the data input and data output in code block 1**: Specify a functioning file path leading to a folder containing pdf/png documents\n",
    "- **Adjust the optional sample_size parameter in code block 2**: Specify the desired sample size or leave empty to consider all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T14:53:31.662985657Z",
     "start_time": "2023-08-29T14:53:31.660812729Z"
    }
   },
   "outputs": [],
   "source": [
    "# code block 1: specify data inputs and outputs\n",
    "INPUT_FOLDER_PATH = os.path.join(\"..\", \"data\", \"nrw\", \"pdfs\")\n",
    "OUTPUT_FILENAME_CSV = os.path.join(\"..\", \"data\", \"nrw\", \"text\", \"test_nrw_all.csv\")\n",
    "OUTPUT_FILENAME_JSON = os.path.join(\"..\", \"data\", \"nrw\", \"text\", \"test_nrw_all.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse PDFs from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T14:53:41.385984734Z",
     "start_time": "2023-08-29T14:53:36.933260644Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 17:03:49.502 | INFO     | data_pipeline.pdf_scraper.tika_pdf_scraper:pdf_parser_from_folder:64 - Parsing file: 2368027_8.pdf\n",
      "2023-09-18 17:03:50,775 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n",
      "2023-09-18 17:04:04.482 | INFO     | data_pipeline.pdf_scraper.tika_pdf_scraper:pdf_parser_from_folder:64 - Parsing file: 2368027_6.pdf\n",
      "2023-09-18 17:04:04.867 | INFO     | data_pipeline.pdf_scraper.tika_pdf_scraper:pdf_parser_from_folder:64 - Parsing file: 2220502_14.pdf\n",
      "2023-09-18 17:04:04.957 | INFO     | data_pipeline.pdf_scraper.tika_pdf_scraper:pdf_parser_from_folder:75 - Parsing done.\n"
     ]
    }
   ],
   "source": [
    "# code block 2: apply pdf_parser function to folder containing pdfs\n",
    "parsed_df = pdf_parser_from_folder(folder_path=INPUT_FOLDER_PATH,\n",
    "                                   sample_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>content</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2368027_8.pdf</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
       "      <td>{'pdf:PDFVersion': '1.6', 'xmp:CreatorTool': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2368027_6.pdf</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
       "      <td>{'pdf:PDFVersion': '1.6', 'xmp:CreatorTool': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2220502_14.pdf</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
       "      <td>{'pdf:unmappedUnicodeCharsPerPage': ['0', '0']...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename                                            content  \\\n",
       "0   2368027_8.pdf  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...   \n",
       "1   2368027_6.pdf  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...   \n",
       "2  2220502_14.pdf  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...   \n",
       "\n",
       "                                            metadata  \n",
       "0  {'pdf:PDFVersion': '1.6', 'xmp:CreatorTool': '...  \n",
       "1  {'pdf:PDFVersion': '1.6', 'xmp:CreatorTool': '...  \n",
       "2  {'pdf:unmappedUnicodeCharsPerPage': ['0', '0']...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code block 3: check results\n",
    "parsed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write results to CSV and json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block 4:\n",
    "# write results to csv\n",
    "parsed_df.to_csv(OUTPUT_FILENAME_CSV, header=True, index=False)\n",
    "\n",
    "# write results to json\n",
    "result_json = parsed_df.to_json(orient='records')\n",
    "\n",
    "with open(OUTPUT_FILENAME_JSON, 'w') as outputfile:\n",
    "    outputfile.write(result_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "landsealing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
